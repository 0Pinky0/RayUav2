algo_name: PPO
ckpt: null
environment:
  env: CartPolePixels
rl_module:
  model_config_dict:
    uses_new_env_runners: True
    vf_share_layers: False
#    conv_filters: [ [ 16, 4, 2 ], [ 32, 4, 2 ], [ 64, 4, 2 ], [ 128, 4, 2 ] ]
#    conv_activation: "relu"
#    post_fcnet_hiddens: [ 256 ]
training:
  lr: 3.0e-4
  gamma: 0.99
  train_batch_size: 2048
  # Algo Specific
  sgd_minibatch_size: 128
  lambda_: 0.95
  clip_param: 0.1
  vf_loss_coeff: 0.5
  entropy_coeff: 0.003
  num_sgd_iter: 5
  vf_clip_param: 100
stop:
  env_runners/episode_return_mean: 70.0
#  training_iteration: 100
#  num_env_steps_sampled_lifetime: 5_000_000