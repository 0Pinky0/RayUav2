algo_name: DQN
ckpt: null
environment:
  env: CartPole-v1
training:
  model:
    uses_new_env_runners: True
  lr: 3.0e-4
  gamma: 0.99
  train_batch_size: 128
  # Algo Specific
  target_network_update_freq: 40
  num_steps_sampled_before_learning_starts: 1_000
  dueling: True
  double_q: True
  n_step: 1
  epsilon: [ [ 0, 0.9 ], [ 10_000, 0.01 ] ]
  td_error_loss_fn: mse
  replay_buffer_config:
    type: PrioritizedEpisodeReplayBuffer
    capacity: 10_000
    alpha: 0.9
    beta: 0.6
stop:
  env_runners/episode_return_mean: 400.0
#  training_iteration: 100
#  num_env_steps_sampled_lifetime: 5_000_000